{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1 - Which states have more/less monitors? (Rank states!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|state|count|\n",
      "+-----+-----+\n",
      "|   06|  170|\n",
      "|   48|  133|\n",
      "|   27|   94|\n",
      "|   26|   92|\n",
      "|   39|   91|\n",
      "|   36|   67|\n",
      "|   45|   64|\n",
      "|   30|   62|\n",
      "|   42|   61|\n",
      "|   12|   55|\n",
      "|   18|   52|\n",
      "|   08|   51|\n",
      "|   37|   50|\n",
      "|   17|   49|\n",
      "|   53|   43|\n",
      "|   22|   41|\n",
      "|   04|   38|\n",
      "|   20|   37|\n",
      "|   13|   35|\n",
      "|   21|   34|\n",
      "|   41|   32|\n",
      "|   01|   31|\n",
      "|   47|   29|\n",
      "|   55|   26|\n",
      "|   34|   24|\n",
      "|   50|   23|\n",
      "|   40|   22|\n",
      "|   23|   21|\n",
      "|   28|   21|\n",
      "|   25|   19|\n",
      "|   51|   19|\n",
      "|   29|   18|\n",
      "|   19|   18|\n",
      "|   80|   18|\n",
      "|   35|   18|\n",
      "|   16|   17|\n",
      "|   33|   17|\n",
      "|   24|   17|\n",
      "|   09|   15|\n",
      "|   44|   13|\n",
      "|   02|   12|\n",
      "|   49|   12|\n",
      "|   05|   11|\n",
      "|   54|   10|\n",
      "|   32|    9|\n",
      "|   56|    9|\n",
      "|   46|    7|\n",
      "|   38|    7|\n",
      "|   78|    6|\n",
      "|   10|    6|\n",
      "|   31|    6|\n",
      "|   72|    6|\n",
      "|   11|    5|\n",
      "|   15|    5|\n",
      "+-----+-----+\n",
      "\n",
      "CPU times: user 658 ms, sys: 111 ms, total: 769 ms\n",
      "Wall time: 32.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = SparkSession.builder.master('local[*]').appName('words').getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "try:\n",
    "    lines = sc.textFile('epa_hap_daily_summary-small.csv')\n",
    "    l2 = lines.filter(lambda line: len(line) > 0)\n",
    "    header = l2.first() #extract header\n",
    "    #filtrar o header\n",
    "    non_empty_lines = l2.filter(lambda row : row != header) \n",
    "\n",
    "    l3 = non_empty_lines.map(lambda line: line.split(\",\"))\n",
    "    logRows = l3.map(lambda arr: Row(state=arr[0],county_code=arr[1],site_num=arr[2],coord=arr[5]+arr[6]))\n",
    "    logRowsDF = spark.createDataFrame(logRows)\n",
    "    # logRowsDF.printSchema()\n",
    "    logRowsDF.createOrReplaceTempView(\"log\")\n",
    "    logRows2DF = spark.sql(\"SELECT state, count(distinct coord) AS count FROM log GROUP BY state ORDER BY count DESC\")\n",
    "    logRows2DF.show(100)\n",
    "\n",
    "    sc.stop()\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2 - Which counties have the best/worst air quality? (Rank counties considering pollutants’ level!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------------------+\n",
      "|State|County|   AveragePolution|\n",
      "+-----+------+------------------+\n",
      "|   47|   167|            2556.0|\n",
      "|   36|   059|              19.0|\n",
      "|   39|   029| 7.385690735785953|\n",
      "|   30|   067| 5.611212121212121|\n",
      "|   80|   006|         4.5121875|\n",
      "|   37|   027| 4.116666666666667|\n",
      "|   06|   031|3.9843770491803276|\n",
      "|   06|   039|            3.7393|\n",
      "|   37|   069|3.3499999999999996|\n",
      "|   08|   059|              3.07|\n",
      "|   26|   125| 2.888877848101266|\n",
      "|   17|   097| 2.879328647058823|\n",
      "|   12|   031|2.7794603978494625|\n",
      "|   25|   017|2.6500000000000004|\n",
      "|   20|   093|2.3753333333333333|\n",
      "|   42|   017|2.3674999999999997|\n",
      "|   06|   079|2.3333333333333335|\n",
      "|   37|   065|             2.325|\n",
      "|   20|   145|2.2941176470588234|\n",
      "|   36|   119|          2.239375|\n",
      "|   37|   101|             2.225|\n",
      "|   09|   003|2.0787055896226416|\n",
      "|   37|   077|2.0285714285714285|\n",
      "|   53|   003|             2.025|\n",
      "|   37|   061|               2.0|\n",
      "|   08|   013| 1.960470901234568|\n",
      "|   05|   035|1.9000000000000001|\n",
      "|   37|   199|               1.9|\n",
      "|   06|   037|1.8391350859879247|\n",
      "|   26|   163|1.8262007365148463|\n",
      "|   22|   047|1.8213132266666665|\n",
      "|   37|   033|           1.80075|\n",
      "|   37|   037|               1.8|\n",
      "|   37|   147|1.7999999999999998|\n",
      "|   19|   045|1.7583018867924527|\n",
      "|   06|   025|1.6478600515463917|\n",
      "|   30|   043| 1.592159090909091|\n",
      "|   06|   033| 1.577142857142857|\n",
      "|   55|   089|        1.55733332|\n",
      "|   30|   095|1.5384615384615385|\n",
      "|   27|   035| 1.532046511627907|\n",
      "|   22|   051|1.5020496153846155|\n",
      "|   21|   019| 1.485702254901961|\n",
      "|   34|   015|1.4814285714285715|\n",
      "|   21|   101|1.4295509090909093|\n",
      "|   01|   117|1.3927777777777777|\n",
      "|   23|   011|             1.375|\n",
      "|   06|   099|1.2781941269841275|\n",
      "|   19|   139|            1.2375|\n",
      "|   30|   023|1.2135793388429752|\n",
      "|   08|   077|1.2109524924242425|\n",
      "|   53|   063|1.1469733510638298|\n",
      "|   22|   033|1.1444728456659612|\n",
      "|   48|   201|1.1426282723128096|\n",
      "|   49|   011|1.1418481240188378|\n",
      "|   30|   071|1.1414093959731544|\n",
      "|   26|   157|     1.13696140625|\n",
      "|   16|   069|1.1226492795389047|\n",
      "|   72|   021|1.1200363636363637|\n",
      "|   26|   139|         1.1110375|\n",
      "|   23|   031|1.0842636320754717|\n",
      "|   27|   117|1.0807463414634146|\n",
      "|   20|   209|1.0779660104986872|\n",
      "|   18|   089|1.0760213851902174|\n",
      "|   34|   017|         1.0754546|\n",
      "|   48|   491|1.0616129032258064|\n",
      "|   29|   510|1.0544578440366965|\n",
      "|   27|   173|1.0511541666666666|\n",
      "|   06|   077|1.0142639721936149|\n",
      "|   05|   091| 1.011219512195122|\n",
      "|   48|   135|1.0014370984405456|\n",
      "|   41|   047|0.9826868292682926|\n",
      "|   20|   181|0.9735323943661971|\n",
      "|   22|   089|0.9709866896551724|\n",
      "|   39|   085|0.9666666666666668|\n",
      "|   27|   111|0.9641929203539823|\n",
      "|   06|   029|0.9552840147731252|\n",
      "|   48|   141|0.9464559802761305|\n",
      "|   20|   091|0.9374867924528303|\n",
      "|   34|   021|0.9314939589041096|\n",
      "|   20|   029|0.9306044444444446|\n",
      "|   08|   035|0.9266666666666667|\n",
      "|   12|   099|0.9141428571428573|\n",
      "|   13|   089|0.9125199496626882|\n",
      "|   27|   061|0.8895128205128204|\n",
      "|   27|   103| 0.881576923076923|\n",
      "|   09|   001|0.8765945608108108|\n",
      "|   25|   013|0.8682349224043717|\n",
      "|   06|   019|0.8499170323179771|\n",
      "|   27|   141|0.8408257575757577|\n",
      "|   55|   079|0.8367436675461741|\n",
      "|   08|   045|0.8351016949152542|\n",
      "|   45|   049|0.8288424908424908|\n",
      "|   41|   051|0.8102990317052269|\n",
      "|   28|   059|        0.81023825|\n",
      "|   09|   013|0.8060031923076922|\n",
      "|   53|   015| 0.802640243902439|\n",
      "|   80|   002|0.8018910386965376|\n",
      "|   22|   017|             0.798|\n",
      "|   25|   005|0.7900226190476192|\n",
      "+-----+------+------------------+\n",
      "only showing top 100 rows\n",
      "\n",
      "CPU times: user 376 ms, sys: 61.5 ms, total: 438 ms\n",
      "Wall time: 13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = SparkSession.builder.master('local[*]').appName('words').getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "try:\n",
    "    lines = sc.textFile('epa_hap_daily_summary-small.csv')\n",
    "    l2 = lines.filter(lambda line: len(line) > 0)\n",
    "    header = l2.first() #extract header\n",
    "    #filtrar o header\n",
    "    non_empty_lines = l2.filter(lambda row : row != header) \n",
    "\n",
    "    l3 = non_empty_lines.map(lambda line: line.split(\",\"))\n",
    "    logRows = l3.map(lambda arr: Row(State =arr[0], County=arr[1],site_num=arr[2], polutionAvg = float(arr[16])))\n",
    "    logRowsDF = spark.createDataFrame(logRows)\n",
    "    # logRowsDF.printSchema()\n",
    "    logRowsDF.createOrReplaceTempView(\"log2\")\n",
    "    logRows2DF = spark.sql(\"SELECT State, County, avg(polutionAvg) AS AveragePolution FROM log2 GROUP BY State, County ORDER BY AveragePolution DESC\")\n",
    "    logRows2DF.show(100)\n",
    "\n",
    "    sc.stop()\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3 - Which states have the best/worst air quality in each year? (Rank states per year considering pollutants' levels!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+---------------+\n",
      "|year|               state|AveragePolution|\n",
      "+----+--------------------+---------------+\n",
      "|1990|           Wisconsin|            0.0|\n",
      "|1990|       West Virginia|            0.0|\n",
      "|1990|      Virgin Islands|            0.0|\n",
      "|1990|            Oklahoma|            0.0|\n",
      "|1990|              Hawaii|        1.97E-4|\n",
      "|1990|              Nevada|        4.21E-4|\n",
      "|1990|              Alaska|        4.42E-4|\n",
      "|1990|        South Dakota|        5.71E-4|\n",
      "|1990|          Washington|        5.97E-4|\n",
      "|1990|             Wyoming|        6.05E-4|\n",
      "|1990|                Utah|        7.97E-4|\n",
      "|1990|          New Mexico|        8.22E-4|\n",
      "|1990|              Oregon|         8.6E-4|\n",
      "|1990|             Arizona|        8.62E-4|\n",
      "|1990|               Maine|        9.79E-4|\n",
      "|1990|            Colorado|       0.002162|\n",
      "|1990|         Mississippi|       0.002667|\n",
      "|1990|            Missouri|         0.0056|\n",
      "|1990|            Michigan|        0.00656|\n",
      "|1990|         Connecticut|         0.0081|\n",
      "|1990|             Georgia|       0.008367|\n",
      "|1990|         Puerto Rico|        0.01005|\n",
      "|1990|      North Carolina|         0.0143|\n",
      "|1990|             Alabama|       0.024325|\n",
      "|1990|                Iowa|         0.0332|\n",
      "|1990|        Pennsylvania|       0.105963|\n",
      "|1990|                Ohio|       0.135716|\n",
      "|1990|            Illinois|       0.145757|\n",
      "|1990|          New Jersey|       0.293335|\n",
      "|1990|           Minnesota|       0.306488|\n",
      "|1990|          California|       0.411531|\n",
      "|1990|      South Carolina|       0.559814|\n",
      "|1990|District Of Columbia|       0.826151|\n",
      "|1990|            Virginia|       0.845142|\n",
      "|1990|           Louisiana|       0.914595|\n",
      "|1990|              Kansas|       1.140815|\n",
      "|1990|             Florida|       1.276563|\n",
      "|1990|            New York|       1.362972|\n",
      "|1990|               Texas|       1.482472|\n",
      "|1990|             Montana|       2.068679|\n",
      "|1990|       Massachusetts|       3.024682|\n",
      "|1990|             Indiana|       4.098978|\n",
      "|1990|           Tennessee|     170.400931|\n",
      "|1991|                Ohio|            0.0|\n",
      "|1991|            Arkansas|            0.0|\n",
      "|1991|              Alaska|        1.76E-4|\n",
      "|1991|        South Dakota|        2.88E-4|\n",
      "|1991|             Wyoming|        3.26E-4|\n",
      "|1991|                Utah|        3.38E-4|\n",
      "|1991|          New Mexico|        3.99E-4|\n",
      "|1991|              Oregon|        4.14E-4|\n",
      "|1991|              Nevada|        4.83E-4|\n",
      "|1991|       West Virginia|        5.47E-4|\n",
      "|1991|              Hawaii|        6.81E-4|\n",
      "|1991|          Washington|        7.14E-4|\n",
      "|1991|             Georgia|        8.39E-4|\n",
      "|1991|            Kentucky|        8.59E-4|\n",
      "|1991|             Arizona|        8.83E-4|\n",
      "|1991|      Virgin Islands|        9.58E-4|\n",
      "|1991|               Maine|       0.001307|\n",
      "|1991|             Vermont|       0.001559|\n",
      "|1991|            Colorado|       0.002401|\n",
      "|1991|            Illinois|       0.045305|\n",
      "|1991|           Wisconsin|        0.11625|\n",
      "|1991|           Minnesota|       0.158581|\n",
      "|1991|             Florida|        0.19555|\n",
      "|1991|        Pennsylvania|       0.216667|\n",
      "|1991|            Virginia|        0.23651|\n",
      "|1991|           Tennessee|       0.256198|\n",
      "|1991|               Texas|       0.280053|\n",
      "|1991|            Michigan|       0.313686|\n",
      "|1991|            Maryland|       0.319016|\n",
      "|1991|          California|       0.673536|\n",
      "|1991|District Of Columbia|       0.677285|\n",
      "|1991|             Montana|       0.767001|\n",
      "|1991|      South Carolina|       0.798206|\n",
      "|1991|            New York|       0.885283|\n",
      "|1991|              Kansas|       0.918196|\n",
      "|1991|          New Jersey|       1.048555|\n",
      "|1991|           Louisiana|            1.2|\n",
      "|1991|             Indiana|       1.661424|\n",
      "|1992|                Ohio|            0.0|\n",
      "|1992|              Alaska|        1.03E-4|\n",
      "|1992|              Hawaii|        1.89E-4|\n",
      "|1992|               Idaho|        2.34E-4|\n",
      "|1992|          Washington|         2.7E-4|\n",
      "|1992|                Utah|        2.84E-4|\n",
      "|1992|          New Mexico|        3.15E-4|\n",
      "|1992|              Nevada|        3.33E-4|\n",
      "|1992|             Wyoming|        4.66E-4|\n",
      "|1992|            Arkansas|         4.7E-4|\n",
      "|1992|        South Dakota|        4.97E-4|\n",
      "|1992|             Vermont|        4.97E-4|\n",
      "|1992|             Arizona|        5.24E-4|\n",
      "|1992|            Virginia|        5.47E-4|\n",
      "|1992|               Maine|        6.71E-4|\n",
      "|1992|             Georgia|        8.03E-4|\n",
      "|1992|       West Virginia|        8.24E-4|\n",
      "|1992|              Oregon|        9.85E-4|\n",
      "|1992|            Kentucky|       0.001314|\n",
      "+----+--------------------+---------------+\n",
      "only showing top 100 rows\n",
      "\n",
      "CPU times: user 111 ms, sys: 91.2 ms, total: 202 ms\n",
      "Wall time: 10.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = SparkSession.builder.master('local[*]').appName('words').getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "try:\n",
    "    epa_daily = sc.textFile('epa_hap_daily_summary-small.csv')\n",
    "\n",
    "    non_empty_lines_epa_daily = epa_daily.filter( lambda line : len(line) > 0 )\n",
    "\n",
    "    header_epa_daily = non_empty_lines_epa_daily.first() #extract header\n",
    "    non_empty_lines_epa_daily = non_empty_lines_epa_daily.filter(lambda row : row != header_epa_daily)  \n",
    "\n",
    "    epa_daily = non_empty_lines_epa_daily.map(lambda line: line.split(','))\n",
    "    \n",
    "    #cria tuplos (ano,(estado,ar))\n",
    "    epa_daily=epa_daily.map(lambda coord: Row(year = coord[11].split('-')[0], state = coord[24], airq = float(coord[16])))\n",
    "    \n",
    "    epa_dailyDF = spark.createDataFrame(epa_daily)\n",
    "    \n",
    "\n",
    "    epa_dailyDF.createOrReplaceTempView(\"log\")\n",
    "    \n",
    "    query= \"SELECT year,state,round(avg(airq),6) AS AveragePolution FROM log GROUP BY year,state ORDER BY year,AveragePolution\"\n",
    "    \n",
    "    epa_daily2DF = spark.sql(query)\n",
    "    epa_daily2DF.show(100)\n",
    "    \n",
    "    sc.stop()\n",
    "    \n",
    "except Exception as err:\n",
    "    print (err)\n",
    "    sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4 - For each state, what is the average distance (in km) of the monitors in that state to the state center? For simplicity, assume that 1 degree of latitude or logitude equals to 111 km. (Monitor dispersion per state!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------+\n",
      "|       state|       avgDistance|\n",
      "+------------+------------------+\n",
      "|    Virginia| 715.4327448133683|\n",
      "|      Alaska| 603.6994841759217|\n",
      "|       Texas| 512.1842175513935|\n",
      "|     Vermont|  504.063097911535|\n",
      "|    Illinois|440.85400685379017|\n",
      "|South Dakota| 365.8450815332589|\n",
      "|     Florida| 336.5449260322615|\n",
      "|  California| 328.2265897979527|\n",
      "|    Michigan| 326.4119709194728|\n",
      "|      Nevada|  326.281231608471|\n",
      "|    Nebraska| 307.1412258440534|\n",
      "|      Kansas|292.07954678193937|\n",
      "|       Idaho|289.63520486710013|\n",
      "|     Montana|286.83825138140065|\n",
      "|    New York| 283.7273444433415|\n",
      "|     Wyoming|283.64057827794375|\n",
      "|      Oregon|  268.853544089414|\n",
      "|Pennsylvania|251.41513622817573|\n",
      "|North Dakota|248.42175081028077|\n",
      "|    Oklahoma| 236.8822819002025|\n",
      "+------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = SparkSession.builder.master('local[*]').appName('words').getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "try:\n",
    "    epa_daily = sc.textFile('epa_hap_daily_summary-small.csv')\n",
    "    usa_state = sc.textFile('usa_states.csv')\n",
    "    \n",
    "    usa_state = sc.textFile('usa_states.csv')\n",
    "\n",
    "    non_empty_lines_epa_daily = epa_daily.filter( lambda line : len(line) > 0 )\n",
    "    non_empty_lines_usa_state = usa_state.filter( lambda line : len(line) > 0 )\n",
    "\n",
    "    header_epa_daily = non_empty_lines_epa_daily.first() #extract header\n",
    "    header_usa_state = non_empty_lines_usa_state.first() #extract header\n",
    "\n",
    "\n",
    "\n",
    "    non_empty_lines_epa_daily = non_empty_lines_epa_daily.filter(lambda row : row != header_epa_daily)  \n",
    "    non_empty_lines_usa_state = non_empty_lines_usa_state.filter(lambda row : row != header_usa_state)  \n",
    "\n",
    "    epa_daily = non_empty_lines_epa_daily.map(lambda line: line.split(','))\n",
    "    usa_state = non_empty_lines_usa_state.map(lambda line: line.split(','))\n",
    "    \n",
    "    table_epa_daily=epa_daily.map(lambda arr: Row(state=arr[24],lat=float(arr[5])*111, long=float(arr[6])*111))\n",
    "    table_usa_state=usa_state.map(lambda arr: Row(state=arr[1],lat=(float(arr[2])*111+float(arr[3])*111)/2, long=(float(arr[4])*111+float(arr[5])*111)/2))\n",
    "    \n",
    "    table_epa_daily = spark.createDataFrame(table_epa_daily)\n",
    "    table_usa_state = spark.createDataFrame(table_usa_state)\n",
    "    \n",
    "    table_epa_daily.createOrReplaceTempView(\"table_epa_daily\")\n",
    "    table_usa_state.createOrReplaceTempView(\"table_usa_state\")\n",
    "    \n",
    "    query=\"SELECT table.state,AVG(table.distance) AS avgDistance FROM (SELECT DISTINCT table_epa_daily.state AS state, SQRT(POWER(FLOAT(table_epa_daily.lat)-FLOAT(table_usa_state.lat),2)+POWER(FLOAT(table_epa_daily.long)-FLOAT(table_usa_state.long),2)) AS distance FROM table_epa_daily INNER JOIN table_usa_state ON table_epa_daily.state=table_usa_state.state) table GROUP BY table.state ORDER BY avgDistance DESC\"    \n",
    "    new_table=spark.sql(query)\n",
    "    new_table.show()\n",
    "    sc.stop()\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5 - How many sensors there are per quadrant (NW, NE, SE, SW) in each state? To answer this question, you should approximate each state’s area to a rectangle as defined in the file “usa_satates.csv”, and divide that area in 4 quadrants (NW, NE, SE, SW). (Count monitors per sate qudrant!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+--------+\n",
      "|NrMonitors|     stateName|Quadrant|\n",
      "+----------+--------------+--------+\n",
      "|        84|    California|      NE|\n",
      "|        74|      Michigan|      SW|\n",
      "|        72|         Texas|      SW|\n",
      "|        68|    California|      SW|\n",
      "|        50|     Minnesota|      SW|\n",
      "|        43|      New York|      SW|\n",
      "|        36|          Ohio|      NW|\n",
      "|        36|  Pennsylvania|      SW|\n",
      "|        36|       Montana|      NW|\n",
      "|        35|     Louisiana|      SW|\n",
      "|        34|         Texas|      SE|\n",
      "|        33|South Carolina|      NE|\n",
      "|        32|      Illinois|      SE|\n",
      "|        30|          Ohio|      SE|\n",
      "|        27|       Florida|      SE|\n",
      "|        26|North Carolina|      SE|\n",
      "|        25|      Colorado|      SE|\n",
      "|        24|         Texas|      NE|\n",
      "|        23|       Florida|      SW|\n",
      "|        21|     Wisconsin|      SW|\n",
      "|        21|       Georgia|      NE|\n",
      "|        21|     Minnesota|      NW|\n",
      "|        20|    Washington|      NE|\n",
      "|        19|North Carolina|      NE|\n",
      "|        18|        Kansas|      SE|\n",
      "|        18|    New Jersey|      SE|\n",
      "|        18|      Oklahoma|      SE|\n",
      "|        18|South Carolina|      SW|\n",
      "|        18|  Pennsylvania|      NW|\n",
      "|        18|       Indiana|      NE|\n",
      "|        18|       Indiana|      SE|\n",
      "|        17|      Colorado|      NE|\n",
      "|        16|      Maryland|      SE|\n",
      "|        16|       Vermont|      NE|\n",
      "|        16|       Arizona|      SW|\n",
      "|        16|      Kentucky|      NW|\n",
      "|        16|      New York|      NE|\n",
      "|        16|    California|      NW|\n",
      "|        15|    Washington|      NW|\n",
      "|        15|        Oregon|      NE|\n",
      "|        15|          Ohio|      NE|\n",
      "|        14|      Michigan|      SE|\n",
      "|        14|       Alabama|      NE|\n",
      "|        14|      Illinois|      NW|\n",
      "|        13|      Kentucky|      SE|\n",
      "|        13|        Oregon|      NW|\n",
      "|        12|  Rhode Island|      SE|\n",
      "|        12|   Mississippi|      SW|\n",
      "|        12|    New Mexico|      NE|\n",
      "|        12|     Minnesota|      NE|\n",
      "|        12|         Maine|      NW|\n",
      "|        11| Massachusetts|      SE|\n",
      "|        11| New Hampshire|      SW|\n",
      "|        11|     Minnesota|      SE|\n",
      "|        11|       Montana|      SE|\n",
      "|        10|       Arizona|      NE|\n",
      "|        10|South Carolina|      SE|\n",
      "|        10|       Arizona|      NW|\n",
      "|        10|          Ohio|      SW|\n",
      "|        10|       Montana|      NE|\n",
      "|         9|        Kansas|      SW|\n",
      "|         9|     Tennessee|      NE|\n",
      "|         9|      Missouri|      SE|\n",
      "|         8|      Virginia|      SE|\n",
      "|         8|       Indiana|      NW|\n",
      "|         8|        Kansas|      NW|\n",
      "|         8|          Iowa|      SW|\n",
      "|         8|     Tennessee|      SE|\n",
      "|         8|     Tennessee|      NW|\n",
      "|         8|   Connecticut|      NW|\n",
      "|         8|       Indiana|      SW|\n",
      "|         7|         Idaho|      NE|\n",
      "|         7|      Virginia|      SW|\n",
      "|         7|       Alabama|      NW|\n",
      "|         7|         Idaho|      NW|\n",
      "|         6|    Washington|      SE|\n",
      "|         6|          Utah|      NE|\n",
      "|         6|         Maine|      SW|\n",
      "|         6|Virgin Islands|      NW|\n",
      "|         6|          Iowa|      SE|\n",
      "|         5|       Georgia|      SW|\n",
      "|         5|        Nevada|      SW|\n",
      "|         5|       Alabama|      SW|\n",
      "|         5|       Florida|      NE|\n",
      "|         5|       Georgia|      NW|\n",
      "|         5|      New York|      SE|\n",
      "|         5|       Montana|      SW|\n",
      "|         5|      Colorado|      NW|\n",
      "|         5|      Arkansas|      NW|\n",
      "|         5|North Carolina|      SW|\n",
      "|         5|       Alabama|      SE|\n",
      "|         5|       Vermont|      NW|\n",
      "|         5|   Mississippi|      NW|\n",
      "|         5|     Louisiana|      NE|\n",
      "|         5| West Virginia|      NW|\n",
      "|         5|   Connecticut|      SE|\n",
      "|         4|       Georgia|      SE|\n",
      "|         4|    New Jersey|      NW|\n",
      "|         4|      Delaware|      NE|\n",
      "|         4| Massachusetts|      NE|\n",
      "|         4| Massachusetts|      SW|\n",
      "|         4|   Mississippi|      SE|\n",
      "|         4| New Hampshire|      NW|\n",
      "|         4|        Alaska|      SE|\n",
      "|         4|     Tennessee|      SW|\n",
      "|         4|      Missouri|      NE|\n",
      "|         4|   Puerto Rico|      SE|\n",
      "|         4|      Virginia|      NW|\n",
      "|         4|          Iowa|      NW|\n",
      "|         4|  South Dakota|      SW|\n",
      "|         4|  Pennsylvania|      NE|\n",
      "|         4|      Colorado|      SW|\n",
      "|         3|      New York|      NW|\n",
      "|         3|          Utah|      NW|\n",
      "|         3|      Nebraska|      SW|\n",
      "|         3|  Pennsylvania|      SE|\n",
      "|         3| West Virginia|      NE|\n",
      "|         3|      Michigan|      NE|\n",
      "|         3|         Texas|      NW|\n",
      "|         3|  North Dakota|      NW|\n",
      "|         3|      Arkansas|      NE|\n",
      "|         3|          Utah|      SW|\n",
      "|         3|        Alaska|      NW|\n",
      "|         3|South Carolina|      NW|\n",
      "|         3|  South Dakota|      NW|\n",
      "|         3|         Idaho|      SW|\n",
      "|         3|        Oregon|      SE|\n",
      "|         3|       Wyoming|      NE|\n",
      "|         3|      Kentucky|      NE|\n",
      "|         3|        Alaska|      NE|\n",
      "|         3|    New Mexico|      NW|\n",
      "|         3|      Missouri|      SW|\n",
      "|         2|        Hawaii|      NE|\n",
      "|         2|        Alaska|      SW|\n",
      "|         2| West Virginia|      SE|\n",
      "|         2|      Arkansas|      SE|\n",
      "|         2|        Nevada|      SE|\n",
      "|         2|  North Dakota|      NE|\n",
      "|         2|        Kansas|      NE|\n",
      "|         2|      Oklahoma|      SW|\n",
      "|         2|      Nebraska|      NE|\n",
      "|         2|      Illinois|      NE|\n",
      "|         2|      Kentucky|      SW|\n",
      "|         2| New Hampshire|      SE|\n",
      "|         2|   Connecticut|      NE|\n",
      "|         2|        Hawaii|      SE|\n",
      "|         2|      Missouri|      NW|\n",
      "|         2|     Wisconsin|      SE|\n",
      "|         2|        Nevada|      NE|\n",
      "|         2|    California|      SE|\n",
      "|         2|       Wyoming|      NW|\n",
      "|         2|       Wyoming|      SE|\n",
      "|         2|    Washington|      SW|\n",
      "|         2|      Oklahoma|      NE|\n",
      "|         2|      Delaware|      NW|\n",
      "|         2|    New Mexico|      SW|\n",
      "|         2|     Wisconsin|      NE|\n",
      "|         2|         Maine|      SE|\n",
      "|         2|       Wyoming|      SW|\n",
      "|         2|       Arizona|      SE|\n",
      "|         1|        Hawaii|      SW|\n",
      "|         1|        Oregon|      SW|\n",
      "|         1|      Arkansas|      SW|\n",
      "|         1|       Vermont|      SE|\n",
      "|         1|  North Dakota|      SW|\n",
      "|         1|  North Dakota|      SE|\n",
      "|         1|       Vermont|      SW|\n",
      "|         1|    New Mexico|      SE|\n",
      "|         1|     Wisconsin|      NW|\n",
      "|         1|         Maine|      NE|\n",
      "|         1|   Puerto Rico|      NE|\n",
      "|         1|      Michigan|      NW|\n",
      "|         1|      Nebraska|      SE|\n",
      "|         1|      Illinois|      SW|\n",
      "|         1|     Louisiana|      NW|\n",
      "|         1|  Rhode Island|      NE|\n",
      "|         1|   Puerto Rico|      NW|\n",
      "|         1|      Maryland|      NE|\n",
      "|         1|    New Jersey|      SW|\n",
      "|         1|    New Jersey|      NE|\n",
      "+----------+--------------+--------+\n",
      "\n",
      "CPU times: user 592 ms, sys: 96.4 ms, total: 689 ms\n",
      "Wall time: 18.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = SparkSession.builder.master('local[*]').appName('words').getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "try:\n",
    "    \n",
    "    ########## Ter USA States com latitude e longitude medias ########## \n",
    "\n",
    "    usaStates = sc.textFile('usa_states.csv')\n",
    "    \n",
    "    non_empty_linesStates = usaStates.filter( lambda line : len(line) > 0 )    \n",
    "    header = non_empty_linesStates.first() #extract header\n",
    "    #filtrar o header\n",
    "    non_empty_linesStates = non_empty_linesStates.filter(lambda row : row != header)  \n",
    "    wordsUSA = non_empty_linesStates.map( lambda line : line.split(','))\n",
    "\n",
    "    linhasUSA = wordsUSA.map(lambda arr: Row(stateNameUSA=arr[1] ,avgLat = (float(arr[2])+float(arr[3]))/2 , avgLong = (float(arr[4])+float(arr[5]))/2))\n",
    "\n",
    "    linhasUSADF = spark.createDataFrame(linhasUSA)\n",
    "    linhasUSADF.createOrReplaceTempView(\"logUSA\")\n",
    "\n",
    "    #######################\n",
    "\n",
    "    epaFile = sc.textFile('epa_hap_daily_summary-small.csv')\n",
    "    \n",
    "    non_empty_linesEPA = epaFile.filter( lambda line : len(line) > 0 )    \n",
    "    header = non_empty_linesEPA.first() #extract header\n",
    "    #filtrar o header\n",
    "    non_empty_linesEPA = non_empty_linesEPA.filter(lambda row : row != header)  \n",
    "    wordsEPA = non_empty_linesEPA.map( lambda line : line.split(','))\n",
    "\n",
    "    linhasEPA = wordsEPA.map(lambda arr: Row(stateName=arr[24] , lat = float(arr[5]) , long = float(arr[6])))\n",
    "    linhasEPADF = spark.createDataFrame(linhasEPA)\n",
    "    linhasEPADF.createOrReplaceTempView(\"logEPA\")\n",
    "    \n",
    "    logRowsEPA = spark.sql(\"SELECT COUNT (DISTINCT stateName, lat, long) as NrMonitors, stateName,\\\n",
    "                        CASE WHEN ((lat <= avgLat) AND (long <= avgLong)) THEN 'NW' \\\n",
    "                            WHEN ((lat <= avgLat) AND (long > avgLong)) THEN 'SW' \\\n",
    "                            WHEN ((lat > avgLat) AND (long <= avgLong)) THEN 'NE' \\\n",
    "                            WHEN ((lat > avgLat) AND (long > avgLong)) THEN 'SE' \\\n",
    "                        END as Quadrant\\\n",
    "                        FROM logUSA INNER JOIN logEPA ON logUSA.stateNameUSA = logEPA.stateName\\\n",
    "                        GROUP BY stateName, Quadrant\\\n",
    "                        ORDER BY NrMonitors DESC\")\n",
    "                           \n",
    "    logRowsEPA.show(10000)\n",
    "\n",
    "    sc.stop()\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
